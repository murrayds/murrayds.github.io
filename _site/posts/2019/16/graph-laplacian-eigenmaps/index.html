

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Graph Laplacian Eigenmaps - Dakota Murray</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Dakota Murray">
<meta property="og:title" content="Graph Laplacian Eigenmaps">


  <link rel="canonical" href="http://localhost:4000/murrayds/posts/2019/16/graph-laplacian-eigenmaps/">
  <meta property="og:url" content="http://localhost:4000/murrayds/posts/2019/16/graph-laplacian-eigenmaps/">



  <meta property="og:description" content="Graph laplacian eigenmaps (GLE) are one means, among many, of embedding graphs into a low-dimensional numeric space. Specifically, GLE is an approach based on Matrix Factorization that takes as input non-relational data and outputs node embeddings. The key insight of GLEs is that the graph property to be preserved can be interpreted as pairwise node similarities. Thus, a larger penalty is imposed if two nodes with large similarity are embedded far apart. Thus, the goal of this approach is to find an embedding that minimizes this penalty.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2019-09-16T00:00:00+00:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Dakota Murray",
      "url" : "http://localhost:4000/murrayds",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/murrayds/feed.xml" type="application/atom+xml" rel="alternate" title="Dakota Murray Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/murrayds/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/murrayds/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/murrayds/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/murrayds/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/murrayds/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/murrayds/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/murrayds/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/murrayds/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/murrayds/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/murrayds/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/murrayds/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/murrayds/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/murrayds/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/murrayds/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/murrayds/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/murrayds/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/murrayds/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/murrayds/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/murrayds/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <div>
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/murrayds/">Dakota Murray</a></li>
          </div>
            <div>
            
              
              <li class="masthead__menu-item"><a href="http://localhost:4000/murrayds/publications/">Publications</a></li>
            
              
              <li class="masthead__menu-item"><a href="http://localhost:4000/murrayds/talks/">Talks</a></li>
            
              
              <li class="masthead__menu-item"><a href="http://localhost:4000/murrayds/year-archive/">Blog</a></li>
            
              
              <li class="masthead__menu-item"><a href="https://www.dropbox.com/s/7kxlqu2qx25wbhm/cv.pdf?dl=0">CV</a></li>
            
            </div>

        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/murrayds/images/headshot_minimal.jpg" class="author__avatar" alt="Dakota Murray">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Dakota Murray</h3>
    <p class="author__bio">Postdoc @ CCNR, Northeastern University</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><a href="https://www.google.com/maps/place/177+Huntington+Ave,+Boston,+MA+02115/@42.3449303,-71.0849754"> <i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Boston</a></li>
      
      
      
      
        <li><a href="mailto:dakota.s.murray@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
        <li><a href="https://twitter.com/dakotasmurray"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/murrayds"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=sgTiLBUAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
        <li><a href="http://orcid.org/0000-0002-7119-0169"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Graph Laplacian Eigenmaps">
    <meta itemprop="description" content="Graph laplacian eigenmaps (GLE) are one means, among many, of embedding graphs into a low-dimensional numeric space. Specifically, GLE is an approach based on Matrix Factorization that takes as input non-relational data and outputs node embeddings. The key insight of GLEs is that the graph property to be preserved can be interpreted as pairwise node similarities. Thus, a larger penalty is imposed if two nodes with large similarity are embedded far apart. Thus, the goal of this approach is to find an embedding that minimizes this penalty.">
    <meta itemprop="datePublished" content="September 16, 2019">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Graph Laplacian Eigenmaps
</h1>

        

        
          <span class="page__meta"><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> <time datetime="2019-09-16T00:00:00+00:00">September 16, 2019</time></span>
        

        
          <span class="page__meta">  — </span>
          <span class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  4 minute read
	
</span>
        


        

        </header>
      

      <section class="page__content" itemprop="text">
        <p>Graph laplacian eigenmaps (GLE) are one means, among many, of embedding graphs into a low-dimensional numeric space. Specifically, GLE is an approach based on Matrix Factorization that takes as input non-relational data and outputs node embeddings. The key insight of GLEs is that the graph property to be preserved can be interpreted as pairwise node similarities. Thus, a larger penalty is imposed if two nodes with large similarity are embedded far apart. Thus, the goal of this approach is to find an embedding that minimizes this penalty.</p>

<p>The gist of this approach is that it aims to first represent the graph as a Graph Laplacian Matrix, $L$. $L$ is a means of representing a graph in matrix form following the definition $L = D - W$, where $D$ is the <em>degree matrix</em>, a diagonal matrix containing the degree of each node, and $W$ is the adjacency matrix of weights. Under this representation, all positive values correspond to degrees of the node, and all negative values to the weights of the edges. We then perform a decomposition on $L$ to find its eigenvalues. The eigenvectors corresponding to the smallest of the eigenvalues are used as the embedding.</p>

<p>The optimal embedding, $y^{\ast}$ can be derived from the following objective function,</p>

\[y^{\ast} = \text{argmin}\_{y} \sum\_{i\neq j} (y\_{i} - y\_{j}^{2} W\_{ij}) = \text{argmin}\_{y} y^{T}Ly\]

<p>Where $W_{ij}$ is the similarity matrix between every pair of nodes $v_{i}$ and $v_{j}$. $L$ is the graph laplacian matrix, $D$ is the diagonal matrix for which $D_{ii} = \sum_{i \neq j}W_{ij}$.</p>

<p>The goal of this objective function is to find the embedding, $y^{\ast}$ that minimizes the error compared to the Graph Laplacian Matrix, $L$. One benefit of representing a graph with $L$ rather than a simple adjacency matrix is that the diagonal will contain the degrees of the graph; the larger the degree of a node, the more that its row will be “weighted” when computing the objective function. The practical effect is that larger degree nodes will have a greater impact on the embedding than lower-degree nodes.</p>

<p>There are several expansions on this basic optimization, but in each of these variants, the optimal embedding $y^{\prime}$ are the eigenvectors of the laplacian matrix, $\lambda$, which can be calculated by solving the the eigenproblem $Wy = \lambda Dy$.</p>

<p>Arrange the eigenvalues from smallest to largest. The first eigenvalue should be close to zero, and its corresponding eigenvector is not typically used for embedding. Rather, use the remaining eigenvalues and their corresponding eigenvectors to construct the $d$-dimensional embedding. For example, a 3-dimensional embedding can be constructed using the eigenvectors corresponding to the 2nd, 3rd, and 4th smallest eigenvalues. A 2-dimensional embedding can be constructed using the eigenvectors of the 2nd and 3rd smallest eigenvalues.</p>

<p>Lets walk through this process in R.</p>

<p>Consider the Karate network, shown below, which is a popular network exemplifying community structure.</p>

<p><img src="/images/post_images/graph_laplacian_eigenmaps/karate_graph.png" alt="Example image" /></p>

<p>Having loaded this data into R, we can construct the Graph Laplacian Matrix, $L$, from the adjacency matrix $W$ and the degree matrix, $D$.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>W &lt;- as.matrix(as.matrix.network(karate))
D &lt;- diag(rowSums(W))
L &lt;- D - W
</code></pre></div></div>

<p>Then, we can solve the eigenproblem $Wy = \lambda Dy$ and select the eigenvectors corresponding to the 2nd and 3rd smallest eigenvectors to produce an embedding.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>eig &lt;- eigen(L, D)
col_dim &lt;- dim(eig$vectors)[1]
vectors &lt;- eig$vectors[,(col_dim - 1):(col_dim - 2)]
</code></pre></div></div>

<p>The resulting embedding is shown below.</p>

<p><img src="/images/post_images/graph_laplacian_eigenmaps/karate_embed.png" alt="Example image" /></p>

<p>We can see that much of the structure from the original graph also appears in the embedding. As with the network, the embedding demonstrates a clear division between the two communities. Additionally, we see all the nodes that are directly connected to the opposing community are clustered together. Meanwhile, nodes for Actor 5, 6, 7, 11, and 17 are clustered apart form the other clusters, reflecting their somewhat isolated position in the original graph. Similarly, Actor 12 only maintains one connection to Mr. H, and is thus set far apart from the other nodes in the embedding.</p>

<p>There are many uses for graph embeddings. They allow for fast computation of node distances and can serve as effective features for graph-based classification problems.</p>

<p>This content was largely drawn from the following resources,</p>

<blockquote>
  <p>Cai, H., Zheng, V. W., &amp; Chang, K. C.-C. (2017). A Comprehensive Survey of Graph Embedding: Problems, Techniques and Applications. ArXiv:1709.07604 [Cs]. Retrieved from http://arxiv.org/abs/1709.07604</p>
</blockquote>

<blockquote>
  <p>Belkin, M., &amp; Niyogi, P. (2001). Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering. Proceedings of the 14th International Conference on Neural Information Processing Systems: Natural and Synthetic, 585–591. Retrieved from http://dl.acm.org/citation.cfm?id=2980539.2980616</p>
</blockquote>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="http://localhost:4000/murrayds/tags/#embedding" class="page__taxonomy-item" rel="tag">embedding</a><span class="sep">, </span>
    
      
      
      <a href="http://localhost:4000/murrayds/tags/#networks" class="page__taxonomy-item" rel="tag">networks</a>
    
    </span>
  </p>




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/murrayds/posts/2019/16/graph-laplacian-eigenmaps/" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/murrayds/posts/2019/16/graph-laplacian-eigenmaps/" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/murrayds/posts/2019/16/graph-laplacian-eigenmaps/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      <!-- 


  <nav class="pagination">
    
      <a href="#" class="pagination--pager disabled">Previous</a>
    
    
      <a href="http://localhost:4000/murrayds/posts/2021/08/final-dissertation/" class="pagination--pager" title="Defending my dissertation
">Next</a>
    
  </nav>
 -->
    </div>

    
  </article>

  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<!-- <a href="/sitemap/">Sitemap</a> -->
<!-- end custom footer snippets -->

        

<!-- <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/murrayds"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/murrayds/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div> -->

<div class="page__footer-copyright">&copy; 2022 Dakota Murray. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/murrayds/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

